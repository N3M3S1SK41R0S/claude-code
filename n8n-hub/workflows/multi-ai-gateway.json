{
  "name": "NEMESIS - Multi-AI Gateway (OpenAI/Claude/Gemini)",
  "nodes": [
    {
      "parameters": {},
      "id": "ai-gateway",
      "name": "AI Gateway",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 400],
      "webhookId": "ai-gateway"
    },
    {
      "parameters": {
        "functionCode": "// NEMESIS Multi-AI Gateway\n// Routes requests to OpenAI, Claude, or Gemini based on config\n\nconst request = $input.first().json;\n\nconst aiRequest = {\n  request_id: 'AI-' + Date.now(),\n  timestamp: new Date().toISOString(),\n  provider: request.provider || request.model?.split('-')[0] || 'auto',\n  model: request.model || 'auto',\n  prompt: request.prompt || request.message || request.text,\n  system: request.system || request.system_prompt || '',\n  params: {\n    temperature: request.temperature ?? 0.7,\n    max_tokens: request.max_tokens || 2048,\n    top_p: request.top_p ?? 1,\n    stream: request.stream || false\n  },\n  options: {\n    fallback: request.fallback !== false,\n    cache: request.cache !== false,\n    retry: request.retry ?? 3\n  }\n};\n\n// Auto-select provider based on task\nif (aiRequest.provider === 'auto') {\n  const prompt = aiRequest.prompt.toLowerCase();\n  if (prompt.includes('code') || prompt.includes('programming')) {\n    aiRequest.provider = 'anthropic';\n    aiRequest.model = 'claude-3-sonnet-20240229';\n  } else if (prompt.includes('image') || prompt.includes('vision')) {\n    aiRequest.provider = 'openai';\n    aiRequest.model = 'gpt-4-vision-preview';\n  } else {\n    aiRequest.provider = 'google';\n    aiRequest.model = 'gemini-pro';\n  }\n}\n\n// Model mapping\nconst models = {\n  openai: {\n    default: 'gpt-4-turbo-preview',\n    fast: 'gpt-3.5-turbo',\n    vision: 'gpt-4-vision-preview',\n    code: 'gpt-4-turbo-preview'\n  },\n  anthropic: {\n    default: 'claude-3-sonnet-20240229',\n    fast: 'claude-3-haiku-20240307',\n    best: 'claude-3-opus-20240229',\n    code: 'claude-3-sonnet-20240229'\n  },\n  google: {\n    default: 'gemini-pro',\n    vision: 'gemini-pro-vision',\n    fast: 'gemini-pro'\n  }\n};\n\nif (aiRequest.model === 'auto' || aiRequest.model === 'default') {\n  aiRequest.model = models[aiRequest.provider]?.default || 'gpt-4-turbo-preview';\n}\n\nreturn [{ json: aiRequest }];"
      },
      "id": "parse-request",
      "name": "Parse AI Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [500, 400]
    },
    {
      "parameters": {
        "conditions": {
          "string": [{ "value1": "={{ $json.provider }}", "operation": "equals", "value2": "openai" }]
        }
      },
      "id": "route-openai",
      "name": "OpenAI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [750, 200]
    },
    {
      "parameters": {
        "conditions": {
          "string": [{ "value1": "={{ $json.provider }}", "operation": "equals", "value2": "anthropic" }]
        }
      },
      "id": "route-claude",
      "name": "Claude?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [750, 400]
    },
    {
      "parameters": {
        "conditions": {
          "string": [{ "value1": "={{ $json.provider }}", "operation": "equals", "value2": "google" }]
        }
      },
      "id": "route-google",
      "name": "Gemini?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 1,
      "position": [750, 600]
    },
    {
      "parameters": {
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ model: $json.model, messages: [{ role: 'system', content: $json.system || 'You are a helpful assistant.' }, { role: 'user', content: $json.prompt }], temperature: $json.params.temperature, max_tokens: $json.params.max_tokens }) }}",
        "options": { "timeout": 60000 }
      },
      "id": "call-openai",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1000, 150],
      "credentials": { "httpHeaderAuth": { "id": "openai-cred", "name": "OpenAI API" } }
    },
    {
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            { "name": "anthropic-version", "value": "2023-06-01" },
            { "name": "content-type", "value": "application/json" }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ model: $json.model, max_tokens: $json.params.max_tokens, system: $json.system || '', messages: [{ role: 'user', content: $json.prompt }] }) }}",
        "options": { "timeout": 60000 }
      },
      "id": "call-claude",
      "name": "Call Claude",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1000, 350],
      "credentials": { "httpHeaderAuth": { "id": "anthropic-cred", "name": "Anthropic API" } }
    },
    {
      "parameters": {
        "url": "https://generativelanguage.googleapis.com/v1beta/models/{{ $json.model }}:generateContent",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpQueryAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ contents: [{ parts: [{ text: ($json.system ? $json.system + '\\n\\n' : '') + $json.prompt }] }], generationConfig: { temperature: $json.params.temperature, maxOutputTokens: $json.params.max_tokens } }) }}",
        "options": { "timeout": 60000 }
      },
      "id": "call-gemini",
      "name": "Call Gemini",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [1000, 550],
      "credentials": { "httpQueryAuth": { "id": "google-ai-cred", "name": "Google AI Key" } }
    },
    {
      "parameters": {
        "functionCode": "// Normalize AI responses to common format\nconst response = $input.first().json;\nconst request = $('Parse AI Request').first().json;\n\nconst result = {\n  request_id: request.request_id,\n  provider: request.provider,\n  model: request.model,\n  success: true,\n  text: '',\n  usage: {},\n  latency_ms: Date.now() - new Date(request.timestamp).getTime()\n};\n\n// Extract text based on provider\nif (request.provider === 'openai') {\n  result.text = response.choices?.[0]?.message?.content || '';\n  result.usage = {\n    prompt_tokens: response.usage?.prompt_tokens,\n    completion_tokens: response.usage?.completion_tokens,\n    total_tokens: response.usage?.total_tokens\n  };\n  result.finish_reason = response.choices?.[0]?.finish_reason;\n} else if (request.provider === 'anthropic') {\n  result.text = response.content?.[0]?.text || '';\n  result.usage = {\n    input_tokens: response.usage?.input_tokens,\n    output_tokens: response.usage?.output_tokens\n  };\n  result.stop_reason = response.stop_reason;\n} else if (request.provider === 'google') {\n  result.text = response.candidates?.[0]?.content?.parts?.[0]?.text || '';\n  result.finish_reason = response.candidates?.[0]?.finishReason;\n}\n\nif (!result.text && response.error) {\n  result.success = false;\n  result.error = response.error.message || 'Unknown error';\n}\n\nreturn [{ json: result }];"
      },
      "id": "normalize-response",
      "name": "Normalize Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1250, 400]
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{ JSON.stringify($json) }}"
      },
      "id": "respond",
      "name": "Return Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1500, 400]
    }
  ],
  "connections": {
    "AI Gateway": {
      "main": [[{ "node": "Parse AI Request", "type": "main", "index": 0 }]]
    },
    "Parse AI Request": {
      "main": [[
        { "node": "OpenAI?", "type": "main", "index": 0 },
        { "node": "Claude?", "type": "main", "index": 0 },
        { "node": "Gemini?", "type": "main", "index": 0 }
      ]]
    },
    "OpenAI?": {
      "main": [[{ "node": "Call OpenAI", "type": "main", "index": 0 }], []]
    },
    "Claude?": {
      "main": [[{ "node": "Call Claude", "type": "main", "index": 0 }], []]
    },
    "Gemini?": {
      "main": [[{ "node": "Call Gemini", "type": "main", "index": 0 }], []]
    },
    "Call OpenAI": {
      "main": [[{ "node": "Normalize Response", "type": "main", "index": 0 }]]
    },
    "Call Claude": {
      "main": [[{ "node": "Normalize Response", "type": "main", "index": 0 }]]
    },
    "Call Gemini": {
      "main": [[{ "node": "Normalize Response", "type": "main", "index": 0 }]]
    },
    "Normalize Response": {
      "main": [[{ "node": "Return Response", "type": "main", "index": 0 }]]
    }
  },
  "settings": { "executionOrder": "v1" },
  "tags": ["nemesis", "ai", "openai", "claude", "gemini", "gateway"]
}
